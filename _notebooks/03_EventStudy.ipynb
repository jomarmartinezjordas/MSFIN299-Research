{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where your files are located\n",
    "data_dir = \"/Users/jomarjordas/Documents/MSFIN299/MSFIN299-Research/_data/stockdata\"\n",
    "\n",
    "# Read in the index file\n",
    "index_df = pd.read_csv(os.path.join(data_dir, 'psei.csv'))\n",
    "\n",
    "# Calculate the daily returns for the index\n",
    "index_df['returns'] = index_df['price'].pct_change()\n",
    "\n",
    "# Loop through each company file\n",
    "for ticker in ['ac']:\n",
    "    # Read in the company file\n",
    "    company_df = pd.read_csv(os.path.join(data_dir, f'{ticker}.csv'))\n",
    "\n",
    "    # Drop any rows with missing values in the 'price' column\n",
    "    company_df = company_df.dropna(subset=['price'])\n",
    "\n",
    "    # Calculate the daily returns for the company, ignoring missing values\n",
    "    try:\n",
    "        company_df['returns'] = company_df['price'].pct_change(errors='ignore')\n",
    "    except TypeError:\n",
    "        print(f\"Error: Could not calculate returns for {ticker}.csv file. Check for missing or invalid values in the 'price' column.\")\n",
    "\n",
    "    # Merge with index data\n",
    "    merged_df = pd.merge(company_df, index_df, on='date', how='inner')\n",
    "\n",
    "    # Calculate the excess returns\n",
    "    merged_df['excess_return'] = merged_df['returns_x'] - merged_df['returns_y']\n",
    "\n",
    "    # Calculate the expected return using CAPM\n",
    "    X = sm.add_constant(merged_df['returns_y'])\n",
    "    model = sm.OLS(merged_df['excess_return'], X)\n",
    "    results = model.fit()\n",
    "    beta = results.params[1]\n",
    "    market_risk_premium = merged_df['returns_y'].mean() - 0.02 # Assume risk-free rate of 2%\n",
    "    expected_return = 0.02 + beta * market_risk_premium\n",
    "\n",
    "    # Add expected return column to company file\n",
    "    merged_df['exp_return'] = expected_return\n",
    "\n",
    "    # Write merged dataframe back to company file\n",
    "    merged_df.to_csv(os.path.join(data_dir, f'{ticker}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- XPHS:AC: No timezone found, symbol may be delisted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s3/vv9psq2d7nb0zc29tlx4z90m0000gn/T/ipykernel_52254/1394361110.py:25: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Volatility</th>\n",
       "      <th>Mean_Return</th>\n",
       "      <th>Sharpe_Ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Open, High, Low, Close, Adj Close, Volume, Return, Volatility, Mean_Return, Sharpe_Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "def calculate_returns(ticker, start_date, end_date):\n",
    "    # download data from Yahoo Finance\n",
    "    df = yf.download(ticker, start=start_date, end=end_date)\n",
    "\n",
    "    # calculate daily returns\n",
    "    df['Return'] = df['Adj Close'].pct_change()\n",
    "\n",
    "    # calculate rolling 30-day volatility\n",
    "    df['Volatility'] = df['Return'].rolling(30).std() * (252 ** 0.5)\n",
    "\n",
    "    # calculate rolling 30-day mean return\n",
    "    df['Mean_Return'] = df['Return'].rolling(30).mean() * 252\n",
    "\n",
    "    # calculate Sharpe Ratio\n",
    "    df['Sharpe_Ratio'] = df['Mean_Return'] / df['Volatility']\n",
    "\n",
    "    # handle division by zero\n",
    "    df.loc[df['Volatility'] == 0, 'Sharpe_Ratio'] = 0\n",
    "\n",
    "    # remove rows with NaN or inf returns\n",
    "    df = df.dropna(subset=['Return', 'Sharpe_Ratio'])\n",
    "    df = df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "\n",
    "    return df\n",
    "\n",
    "calculate_returns(\"XPHS:AC\",\"2023-04-01\",\"2023-04-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "ticker = \"PSEI.PS\"\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2023-04-13\"\n",
    "\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "data = data[['Close']]  # select only the 'Close' column\n",
    "data_copy = data.copy()  # create a copy of the dataframe\n",
    "data_copy['Date'] = data_copy.index  # add the 'Date' column\n",
    "\n",
    "# specify the path to the folder where you want to save the CSV file\n",
    "path = '/Users/jomarjordas/Documents/MSFIN299/MSFIN299-Research/_data/stockdata'\n",
    "\n",
    "# save the CSV file to the specified folder\n",
    "data_copy.to_csv(path + 'psei.csv', index=False)  # index=False to not include the index in the output file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Applications/anaconda3/envs/msfin299/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/msfin299/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/msfin299/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m company_df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(company_df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Add this code to handle non-numeric values in the 'price' column\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m returns \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(company_df[\u001b[39m'\u001b[39;49m\u001b[39mprice\u001b[39;49m\u001b[39m'\u001b[39;49m], errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mpct_change()\n\u001b[1;32m     23\u001b[0m \u001b[39mif\u001b[39;00m returns\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39many():\n\u001b[1;32m     24\u001b[0m     company_df \u001b[39m=\u001b[39m company_df\u001b[39m.\u001b[39mdropna(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/msfin299/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/msfin299/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'price'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify the directory where your files are located\n",
    "data_dir = \"/Users/jomarjordas/Documents/MSFIN299/MSFIN299-Research/_data/stockdata\"\n",
    "\n",
    "# Read in the index file\n",
    "index_df = pd.read_csv(os.path.join(data_dir, 'psei.csv'))\n",
    "index_df['date'] = pd.to_datetime(index_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Calculate the daily returns for the index\n",
    "index_df['returns'] = index_df['price'].pct_change()\n",
    "\n",
    "# Loop through each company file\n",
    "for ticker in ['ac']:\n",
    "    # Read in the company file\n",
    "    company_df = pd.read_csv(os.path.join(data_dir, f'{ticker}.csv'))\n",
    "    company_df['date'] = pd.to_datetime(company_df['date'], format='%Y-%m-%d')\n",
    "\n",
    "    # Add this code to handle non-numeric values in the 'price' column\n",
    "    returns = pd.to_numeric(company_df['price'], errors='coerce').pct_change()\n",
    "    if returns.isna().any():\n",
    "        company_df = company_df.dropna(subset=['price'])\n",
    "        returns = pd.to_numeric(company_df['price'], errors='coerce').pct_change()\n",
    "    company_df['returns'] = returns\n",
    "\n",
    "    # Merge with index data\n",
    "    merged_df = pd.merge(company_df, index_df, on='date', how='inner')\n",
    "\n",
    "    # Check for and handle missing or invalid values in returns_y\n",
    "    merged_df = merged_df[~merged_df['returns_y'].isna()]\n",
    "    merged_df = merged_df[merged_df['returns_y'] != float('inf')]\n",
    "    merged_df = merged_df[merged_df['returns_y'] != float('-inf')]\n",
    "\n",
    "    # Calculate the excess returns\n",
    "    merged_df['excess_return'] = merged_df['returns_x'] - merged_df['returns_y']\n",
    "\n",
    "    # Calculate the expected return using CAPM\n",
    "    X = sm.add_constant(merged_df['returns_y'])\n",
    "    model = sm.OLS(merged_df['excess_return'], X)\n",
    "    results = model.fit()\n",
    "    beta = results.params[1]\n",
    "    market_risk_premium = merged_df['returns_y'].mean() - 0.02 # Assume risk-free rate of 2%\n",
    "    expected_return = 0.02 + beta * market_risk_premium\n",
    "\n",
    "    # Add expected return column to company file\n",
    "    merged_df['exp_return'] = expected_return\n",
    "\n",
    "    # Calculate the abnormal returns\n",
    "    merged_df['abnormal_return'] = merged_df['excess_return'] - merged_df['exp_return']\n",
    "\n",
    "    # Calculate the cumulative abnormal returns\n",
    "    merged_df['cumulative_abnormal_return'] = merged_df['abnormal_return'].cumsum()\n",
    "\n",
    "    # Write merged dataframe back to company file\n",
    "    merged_df.to_csv(os.path.join(data_dir, f'{ticker}.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msfin299",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
