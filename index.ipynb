{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis using FinBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing classes, directories, and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spacy English language model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory containing the CSV files\n",
    "dir_path = '/Users/jomarjordas/Documents/MSFIN299/MSFIN299-Research/data/17a_exports'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FinBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the input into the FinBERT Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentiment classes and scores\n",
    "sentiment_classes = ['positive', 'neutral', 'negative']\n",
    "sentiment_scores = [1, 0, -1]\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results_doc = []\n",
    "\n",
    "# Iterate through all the text files in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        \n",
    "        # Read the contents of the text file\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read().replace('\\n', '')\n",
    "        \n",
    "        # Tokenize the text using the BERT tokenizer\n",
    "        tokens = tokenizer.encode_plus(text, max_length=512, truncation=True, padding='max_length',\n",
    "                                       add_special_tokens=True, return_tensors='pt')\n",
    "        \n",
    "        # Get the model's output for the tokenized text\n",
    "        output = model(**tokens)\n",
    "        \n",
    "        # Apply softmax to the logits output tensor of our model (in index 0) across dimension -1\n",
    "        probs = F.softmax(output[0], dim=-1)\n",
    "        \n",
    "        # Get the index of the predicted sentiment class\n",
    "        pred_class_idx = torch.argmax(probs, dim=1)\n",
    "        \n",
    "        # Map the predicted sentiment class to a sentiment score and interpretation\n",
    "        sentiment_score = sentiment_scores[pred_class_idx.item()]\n",
    "        interpretation = sentiment_classes[pred_class_idx.item()]\n",
    "\n",
    "        # Extract ticker and year from the filename using regex\n",
    "        ticker = re.findall(r'^([A-Za-z]+)_\\d{4}\\.txt$', filename)[0]\n",
    "        year = re.findall(r'^[A-Za-z]+_(\\d{4})\\.txt$', filename)[0]\n",
    "        \n",
    "        # Add the sentiment score and interpretation to the list of results\n",
    "        results_doc.append({'file_name': filename, 'ticker': ticker, 'year': year, 'sentiment_score': sentiment_score, 'interpretation': interpretation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>year</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEG_2021.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEG_2020.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEG_2019.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEG_2018.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEG_2017.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name ticker  year  sentiment_score interpretation\n",
       "2  MEG_2021.txt    MEG  2021                1       positive\n",
       "1  MEG_2020.txt    MEG  2020                0        neutral\n",
       "3  MEG_2019.txt    MEG  2019                1       positive\n",
       "4  MEG_2018.txt    MEG  2018                1       positive\n",
       "0  MEG_2017.txt    MEG  2017                1       positive"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with the sentiment score and interpretation for each file\n",
    "df_results_doc = pd.DataFrame(results_doc)\n",
    "\n",
    "# Print the results dataframe\n",
    "df = df_results_doc.sort_values('year', ascending=False)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sentiment scores and classes\n",
    "sentiment_scores_sent = [1, 0, -1]\n",
    "sentiment_classes_sent = ['positive', 'neutral', 'negative']\n",
    "\n",
    "# Initialize the results list and counters\n",
    "results_sent = []\n",
    "pos_count = 0\n",
    "neu_count = 0\n",
    "neg_count = 0\n",
    "\n",
    "# Loop over each text file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "\n",
    "        # Read the contents of the text file\n",
    "        with open(file_path, 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Use Spacy to split the text into sentences\n",
    "        doc = nlp(text)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "\n",
    "        # Initialize the sentence-level results list and counters\n",
    "        sentence_results = []\n",
    "        pos_sent_count = 0\n",
    "        neu_sent_count = 0\n",
    "        neg_sent_count = 0\n",
    "\n",
    "        # Loop over each sentence in the text file\n",
    "        for sentence in sentences:\n",
    "            # Tokenize the sentence using the FinBERT tokenizer\n",
    "            tokens = tokenizer.encode_plus(sentence, max_length=512, truncation=True, padding='max_length',\n",
    "                                           add_special_tokens=True, return_tensors='pt')\n",
    "\n",
    "            # Get the model's output for the tokenized sentence\n",
    "            output = model(**tokens)\n",
    "\n",
    "            # Apply softmax to the logits output tensor of our model (in index 0) across dimension -1\n",
    "            probs = F.softmax(output[0], dim=-1)\n",
    "\n",
    "            # Get the index of the predicted sentiment class\n",
    "            pred_class_idx = torch.argmax(probs, dim=1)\n",
    "\n",
    "            # Map the predicted sentiment class to a sentiment score and interpretation\n",
    "            sentiment_score = sentiment_scores_sent[pred_class_idx.item()]\n",
    "            if sentiment_score < -0.05:\n",
    "                interpretation = 'negative'\n",
    "            elif sentiment_score > 0.05:\n",
    "                interpretation = 'positive'\n",
    "            else:\n",
    "                interpretation = 'neutral'\n",
    "\n",
    "            # Add the sentiment score and interpretation to the sentence-level results list\n",
    "            sentence_results.append({'sentence': sentence.strip(), 'sentiment_score': sentiment_score, 'interpretation': interpretation})\n",
    "\n",
    "            # Update the sentence-level sentiment counters\n",
    "            if interpretation == 'positive':\n",
    "                pos_sent_count += 1\n",
    "            elif interpretation == 'neutral':\n",
    "                neu_sent_count += 1\n",
    "            elif interpretation == 'negative':\n",
    "                neg_sent_count += 1\n",
    "\n",
    "        # Calculate the overall sentiment score for the corpus\n",
    "        sentiment_score_corpus = (pos_sent_count - neg_sent_count) / len(sentences)\n",
    "\n",
    "        # Extract ticker and year from the filename using regex\n",
    "        ticker = re.findall(r'^([A-Za-z]+)_\\d{4}\\.txt$', filename)[0]\n",
    "        year = re.findall(r'^[A-Za-z]+_(\\d{4})\\.txt$', filename)[0]\n",
    "\n",
    "        # Add the sentence-level and file-level results to the results list\n",
    "        results_sent.append({'file_name': filename, 'ticker': ticker, 'year': year, \n",
    "                              'sentences': sentence_results, \n",
    "                              'positive_sent_count': pos_sent_count,\n",
    "                              'neutral_sent_count': neu_sent_count,\n",
    "                              'negative_sent_count': neg_sent_count,\n",
    "                              'sentiment_score_corpus': sentiment_score_corpus,\n",
    "                              'corpus_interpretation': 'positive' if sentiment_score_corpus > 0.05 else ('neutral' if -0.05 <= sentiment_score_corpus <= 0.05 else 'negative')})\n",
    "        \n",
    "        # Update the file-level sentiment counters\n",
    "        pos_count += pos_sent_count\n",
    "        neu_count += neu_sent_count\n",
    "        neg_count += neg_sent_count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe to show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>year</th>\n",
       "      <th>sentences</th>\n",
       "      <th>positive_sent_count</th>\n",
       "      <th>neutral_sent_count</th>\n",
       "      <th>negative_sent_count</th>\n",
       "      <th>sentiment_score_corpus</th>\n",
       "      <th>corpus_interpretation</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MEG_2021.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2021</td>\n",
       "      <td>[{'sentence': 'Megaworld, the country’s larges...</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>neutral</td>\n",
       "      <td>51</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEG_2020.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2020</td>\n",
       "      <td>[{'sentence': 'Megaworld, the country’s larges...</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>negative</td>\n",
       "      <td>52</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEG_2019.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2019</td>\n",
       "      <td>[{'sentence': 'Megaworld, the country’s larges...</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>positive</td>\n",
       "      <td>55</td>\n",
       "      <td>1687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MEG_2018.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2018</td>\n",
       "      <td>[{'sentence': 'Megaworld, the country’s larges...</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>positive</td>\n",
       "      <td>53</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MEG_2017.txt</td>\n",
       "      <td>MEG</td>\n",
       "      <td>2017</td>\n",
       "      <td>[{'sentence': 'Megaworld, the country’s larges...</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>positive</td>\n",
       "      <td>53</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_name ticker  year  \\\n",
       "2  MEG_2021.txt    MEG  2021   \n",
       "1  MEG_2020.txt    MEG  2020   \n",
       "3  MEG_2019.txt    MEG  2019   \n",
       "4  MEG_2018.txt    MEG  2018   \n",
       "0  MEG_2017.txt    MEG  2017   \n",
       "\n",
       "                                           sentences  positive_sent_count  \\\n",
       "2  [{'sentence': 'Megaworld, the country’s larges...                   23   \n",
       "1  [{'sentence': 'Megaworld, the country’s larges...                   17   \n",
       "3  [{'sentence': 'Megaworld, the country’s larges...                   28   \n",
       "4  [{'sentence': 'Megaworld, the country’s larges...                   27   \n",
       "0  [{'sentence': 'Megaworld, the country’s larges...                   30   \n",
       "\n",
       "   neutral_sent_count  negative_sent_count  sentiment_score_corpus  \\\n",
       "2                   7                   21                0.039216   \n",
       "1                  14                   21               -0.076923   \n",
       "3                   5                   22                0.109091   \n",
       "4                   4                   22                0.094340   \n",
       "0                   4                   19                0.207547   \n",
       "\n",
       "  corpus_interpretation  sentence_count  token_count  \n",
       "2               neutral              51         1642  \n",
       "1              negative              52         1603  \n",
       "3              positive              55         1687  \n",
       "4              positive              53         1868  \n",
       "0              positive              53         1800  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pandas DataFrame from the results list\n",
    "df = pd.DataFrame(results_sent)\n",
    "\n",
    "# Add a column for the total sentence count\n",
    "df['sentence_count'] = df['sentences'].apply(lambda x: len(x))\n",
    "\n",
    "# Add a column for the total token count\n",
    "df['token_count'] = df['sentences'].apply(lambda x: sum(len(sentence['sentence'].split()) for sentence in x))\n",
    "\n",
    "output_dir_path = '/Users/jomarjordas/Documents/MSFIN299/MSFIN299-Research/data/17a_exports'\n",
    "output_file_name = 'sent_lvl.csv'\n",
    "output_file_path = os.path.join(output_dir_path, output_file_name)\n",
    "\n",
    "# save to csv\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "df = df.sort_values('year', ascending=False)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
